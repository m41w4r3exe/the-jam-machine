{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3vAEjWWI2On"
      },
      "source": [
        "# The Jam Machine \n",
        "\n",
        "In this notebook, you can:\n",
        "\n",
        "- Train the-jam-machine model on your own music dataset from stratch \n",
        "\n",
        "- Generate music using the-jam machine *A-lot-TODO \n",
        "\n",
        "- Finetune a pretrained the-jam-machine model with an additional dataset *TODO\n",
        "\n",
        "Check the-jam-machine on [GitHub](https://github.com/m41w4r3exe/the-jam-machine)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nj3_dbPjL0tB"
      },
      "outputs": [],
      "source": [
        "## THIS NEEDS TO BE CLEANED - NOT EVERYTHING IS NECESSARY\n",
        "# basic packages requirements\n",
        "!pip install wandb\n",
        "import os\n",
        "from pathlib import Path\n",
        "import glob\n",
        "import random\n",
        "import shutil\n",
        "import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import typing\n",
        "# tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import preprocessing\n",
        "from tensorflow.keras import models, layers\n",
        "tf.config.list_physical_devices(\"GPU\")\n",
        "# transformers\n",
        "!pip install transformers tokenizers\n",
        "from transformers import PreTrainedTokenizerFast\n",
        "from transformers import DataCollatorForLanguageModeling\n",
        "from transformers import GPT2Config, GPT2LMHeadModel\n",
        "from transformers import TrainingArguments, Trainer\n",
        "# tokenizer\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import BPE\n",
        "from tokenizers.trainers import BpeTrainer\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "# torch\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3sLiMIs8If3",
        "outputId": "c31dba27-08a8-4458-9757-8bb5a444fcc6"
      },
      "outputs": [],
      "source": [
        "#@title Setup requirements\n",
        "!git clone https://github.com/m41w4r3exe/the-jam-machine.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7E3OcLoLSLM"
      },
      "outputs": [],
      "source": [
        "# move into the git folder to have all scripts in the local folder\n",
        "os.chdir(\"./the-jam-machine\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Cvv_l0vK92H",
        "outputId": "59d08332-fbeb-4b28-a917-f3c6622b3b89"
      },
      "outputs": [],
      "source": [
        "# check that we re in the right happy place\n",
        "print(f\"Current working directory: {os.getcwd()}\")\n",
        "print(f\"Files and Folders in directory:\")\n",
        "os.listdir()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Od892Wl9K_X4"
      },
      "outputs": [],
      "source": [
        "# install requirements\n",
        "# !pipenv lock -r > requirements.txt\n",
        "# !pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiAZ05cXL4d4"
      },
      "source": [
        "Have a folder ready with a collection of midi files to train on colab, in a google drive folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqyUJuM7LuBR",
        "outputId": "3017074a-55a5-4f72-d64a-2de56f99f9b1"
      },
      "outputs": [],
      "source": [
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLfXX3QvNi6J"
      },
      "outputs": [],
      "source": [
        "# path = Path('/gdrive/My Drive/')\n",
        "# drive_jam_machine_path = Path(\"/content/drive/MyDrive/the_jam_machine\")\n",
        "# data_path = Path(f\"{drive_jam_machine_path}/data\") \n",
        "drive_path = Path(\"/content/drive/MyDrive/the_jam_machine/\")\n",
        "midi_path = Path(f\"{drive_path}/midi_data\")\n",
        "# encoded_midi_path = Path(f\"{drive_path}/midi_encoded\")\n",
        "encoded_midi_path = Path(f\"{drive_path}/midi_encoded_by_tristan\")\n",
        "tokenizer_path = Path(f\"{drive_path}/tokenizer\")\n",
        "model_path = Path(f\"{drive_path}/model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMYRN_OiM7P6"
      },
      "outputs": [],
      "source": [
        "# #@title Path definition\n",
        "\n",
        "# #@markdown Specify the path of the audio files to use preprocess for training\n",
        "# midi_path = Path(\"/content/drive/MyDrive/the_jam_machine/midi_data\") #@param {type:\"string\"}\n",
        "\n",
        "# #@markdown (Optional) If you wish to save encodings to a different folder (maybe to your google drive to re-use them later) specify a path here\n",
        "# encoded_midi_path = Path(\"/content/drive/MyDrive/the_jam_machine/midi_encoded\") #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gwWdCMCeLPS"
      },
      "source": [
        "# Encoding Midi into Text (Done already)\n",
        "from `mymusic.mid` files from `midi_path` to `music.txt` files in `encoded_midi_path`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IX9A654ucg-u"
      },
      "outputs": [],
      "source": [
        "#@title File encoding\n",
        "#!python encoder_mlike.py --midi_path {midi_path} --encoded_midi_path {encoded_midi_path}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpXIJDq8dyf3"
      },
      "source": [
        "# Dataset\n",
        "- load the encoded data\n",
        "- training set - ?? % (done already by Tristan's encoding)\n",
        "- validation set - ?? % (done already by Tristan's encoding)\n",
        "\n",
        "- Tokenizing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_0WBWxkLrMu"
      },
      "source": [
        "## Loading the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9aHR_xAaGjJ"
      },
      "source": [
        "Define data path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_OQCLKYhI27l"
      },
      "outputs": [],
      "source": [
        "dataset_path = encoded_midi_path;\n",
        "dataset_path_all = os.path.join(dataset_path, \"all\")\n",
        "dataset_path_train = os.path.join(dataset_path, \"train\")\n",
        "dataset_path_valid = os.path.join(dataset_path, \"valid\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmAxbkVkaLMz"
      },
      "source": [
        "Training and Validation set definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t89OLG4JaDCZ"
      },
      "outputs": [],
      "source": [
        "# TO DO - Tristan's dataset is already splitted - code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81ybSjEnaWCr"
      },
      "source": [
        "Define individual path for every files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2E31PtNiozA",
        "outputId": "84a4e748-6340-4d66-a285-68b71efe0937"
      },
      "outputs": [],
      "source": [
        "# write full filepath to list\n",
        "def full_filepath_to_list(dataset_folder, file_limit=4):\n",
        "  dataset_files = os.listdir(dataset_folder)\n",
        "  dataset_files = [f\"{dataset_folder}/{file}\" for count, file in enumerate(dataset_files) if count < file_limit]\n",
        "  print(dataset_files)\n",
        "  return dataset_files\n",
        "\n",
        "# dataset root folder\n",
        "# print(os.listdir(dataset_path))\n",
        "# files_all = full_filepath_to_list(dataset_path_all) # all files\n",
        "files_train = full_filepath_to_list(dataset_path_train) # training set\n",
        "files_valid = full_filepath_to_list(dataset_path_valid) # validation set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTrE4x-xLoAC"
      },
      "source": [
        "## Put data into dictionnary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ReqyZyP1GrqG",
        "outputId": "f5112ac8-f0f6-4d59-f02f-f56b2e35f739"
      },
      "outputs": [],
      "source": [
        "# TO CHANGE  - this will probably give us some memory issues \n",
        "# Dictionnary stage to skip here and load the date into the tokenizer directly from the text files\n",
        "# show the first 2 items\n",
        "def show_n_first_dataset_entries(dataset, n=2):\n",
        "  for idx, key in enumerate(dataset.values()):\n",
        "    if idx >= n:\n",
        "      break\n",
        "    else:\n",
        "      print(key)\n",
        "\n",
        "def dataset_in_dictionary(files):\n",
        "  dataset_dict = {}\n",
        "  for count, file in enumerate(files):\n",
        "    filename = file.split(\"/\")\n",
        "    file_content = open(file, \"r\")\n",
        "    while True:\n",
        "      count += 1\n",
        "      line =  file_content.readline().rstrip(\"\\n\") \n",
        "       \n",
        "      if not line: # break when file is over\n",
        "        break\n",
        "\n",
        "      dataset_dict[f\"filename[-1]_{count}\"] = line\n",
        "\n",
        "  show_n_first_dataset_entries(dataset_dict, n=2)\n",
        "\n",
        "  return dataset_dict\n",
        "\n",
        "print(\"=============\")\n",
        "print(\"Training data\")\n",
        "print(\"=============\")\n",
        "dataset_train_dict = dataset_in_dictionary(files_train)\n",
        "print(\"===============\")\n",
        "print(\"Validation data\")\n",
        "print(\"===============\")\n",
        "dataset_valid_dict = dataset_in_dictionary(files_valid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKuQBcHO8DuY"
      },
      "source": [
        "# Tokenizer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJA0Q4e8QKlv"
      },
      "outputs": [],
      "source": [
        "# defined in an earlier cell\n",
        "# tokenizer_path = Path(f\"{drive_path}/tokenizer\")\n",
        "tokenizer_path = tokenizer_path\n",
        "tokenizer_file = \"tokenizer.json\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFtBxLkIsAmr"
      },
      "source": [
        "## Train the TOKENIZER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yY_lCEkGdTQT"
      },
      "outputs": [],
      "source": [
        "#do we train from scratch?\n",
        "train_from_scratch = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbMJtqPJkvJx"
      },
      "outputs": [],
      "source": [
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import WordLevel\n",
        "from tokenizers.pre_tokenizers import WhitespaceSplit\n",
        "from tokenizers.trainers import WordLevelTrainer\n",
        "from transformers import PreTrainedTokenizerFast\n",
        "\n",
        "\n",
        "# making an iterator to go through the dictionary \n",
        "# CHANG THIS TO LOAD DIRECTLY FROM THE FILES TO SAVE MEMORY\n",
        "def get_training_corpus():\n",
        "    for song in dataset_train_dict.values():\n",
        "        yield song\n",
        "\n",
        "def define_and_save_tokenizer(\n",
        "  saved_tokenizer=\"tokenizer.json\", \n",
        "  tokenizer_path=\"./\"\n",
        "):\n",
        "  # using a Word Level Tokemizer\n",
        "  tokenizer = Tokenizer(WordLevel(unk_token=\"[UNK]\"))\n",
        "  # separating vocabulary on whitespaces (pretokenizer)\n",
        "  tokenizer.pre_tokenizer = WhitespaceSplit()\n",
        "  # set up the trainer \n",
        "  trainer = WordLevelTrainer(\n",
        "      special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"]\n",
        "  )\n",
        "  # special tokens I took the ones tristan used but I am not sure I understand all of them \n",
        "  # [UNK] always need and UNK token\n",
        "  # [PAD] if we need to do some pading\n",
        "  # [MASK] if when we need to mask, in order to predict the future without seeing it\n",
        "  # [CLS] what is it?\n",
        "  # [SEP] what is it ?\n",
        "\n",
        "  # get corpus\n",
        "  training_corpus = get_training_corpus()\n",
        "  # train tokenizer\n",
        "  tokenizer.train_from_iterator(training_corpus, trainer=trainer)\n",
        "  # save tokenizer\n",
        "  tokenizer.save(f\"{tokenizer_path}/{saved_tokenizer}\")\n",
        "\n",
        "  return tokenizer\n",
        "\n",
        "if train_from_scratch:\n",
        "  tokenizer = define_and_save_tokenizer(tokenizer_path=tokenizer_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Z_4vy6cPUz7"
      },
      "source": [
        "## Or load the trained tokenizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVfS9F3HPTfx"
      },
      "outputs": [],
      "source": [
        "if not train_from_scratch:\n",
        "  from transformers import PreTrainedTokenizerFast\n",
        "  tokenizer = PreTrainedTokenizerFast(tokenizer_file=f\"{tokenizer_path}/{tokenizer_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-hYSVhWRaCm"
      },
      "source": [
        " ## Make it ready for GPT2 : add the pad_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xEyb48_HRQfb"
      },
      "outputs": [],
      "source": [
        "def format_tokenizer_for_transformers_classes(saved_tokenizer=\"tokenizer.json\"):\n",
        "  # PreTrainedTokenizerFast makes the tokenizer usable by the transformer\n",
        "  tokenizer = PreTrainedTokenizerFast(tokenizer_file = saved_tokenizer)\n",
        "  tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "\n",
        "  return tokenizer\n",
        "\n",
        "tokenizer = format_tokenizer_for_transformers_classes(\n",
        "    saved_tokenizer=f\"{tokenizer_path}/{tokenizer_file}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBW_Rgm8QA_N"
      },
      "source": [
        "## Visualize the Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5r-usDzffae",
        "outputId": "2136653e-0593-4bb0-a826-6a0ff4a34153"
      },
      "outputs": [],
      "source": [
        "print(tokenizer.vocab_size)\n",
        "tokenizer.get_vocab()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEbAC-NKst-b"
      },
      "source": [
        "## Tokenize the DATASET and prepare it for the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBOS6W4ysx0H"
      },
      "outputs": [],
      "source": [
        "def tokenize_function(data_to_tokenize):\n",
        "  # this make the tokenized data ready for the model that requires a\n",
        "    tokenized_data = tokenizer(\n",
        "        data_to_tokenize,\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=512,\n",
        "    ) \n",
        "    return {\n",
        "        \"input_ids\": tokenized_data[\"input_ids\"]\n",
        "    } \n",
        "\n",
        "# tokenize a dataset_dictionnary\n",
        "def tokenize_dataset(dataset_dictionary, tokenizer):\n",
        "  tokenized_dictionary=[]\n",
        "  for file in dataset_dictionary.values():\n",
        "    # print(file)\n",
        "    tokenized_dictionary.append(tokenize_function(file))\n",
        "    # print(encoded_file)\n",
        "  return tokenized_dictionary\n",
        "\n",
        "dataset_train_tokenized = tokenize_dataset(dataset_train_dict,tokenizer)\n",
        "dataset_val_tokenized = tokenize_dataset(dataset_valid_dict,tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djrL5XXDkQKD",
        "outputId": "a7badc3b-459b-4e12-aa9d-3f654aac189a"
      },
      "outputs": [],
      "source": [
        "# checking that the data is in the correct shape to be input to the model\n",
        "assert list(dataset_train_tokenized[0]) == [\"input_ids\"], list(dataset_train_tokenized[0])\n",
        "print(type(dataset_train_tokenized[0]))\n",
        "# Check a few samples\n",
        "for i, ii in enumerate(dataset_train_dict.values()):\n",
        "  if i > 4: # print only the first 5\n",
        "    break\n",
        "  else: \n",
        "    print(\"----\")\n",
        "    print(ii)\n",
        "    print(dataset_train_tokenized[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAlPYX9JcGad"
      },
      "source": [
        "# Define the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEMfCqBWNY6n"
      },
      "source": [
        "## Data collator.\n",
        "[Huggingface](https://huggingface.co/transformers/v4.8.1/main_classes/data_collator.html)\n",
        "\n",
        "\"\n",
        "Data collators are objects that will form a batch by using a list of dataset elements as input. These elements are of the same type as the elements of train_dataset or eval_dataset.\n",
        "\n",
        "To be able to build batches, data collators may apply some processing (like padding). Some of them (like DataCollatorForLanguageModeling) also apply some random data augmentation (like random masking) oin the formed batch.\n",
        "\"\n",
        "\n",
        "\"\n",
        "**class transformers.data.data_collator.DataCollatorForLanguageModeling**\n",
        "- tokenizer (PreTrainedTokenizer or PreTrainedTokenizerFast) – The tokenizer used for encoding the data.\n",
        "- mlm (bool, optional, defaults to True) – Whether or not to use masked language modeling. If set to False, the labels are the same as the inputs with the padding tokens ignored (by setting them to -100). Otherwise, the labels are -100 for non-masked tokens and the value to predict for the masked token\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpCBw5H5Tb2L"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForLanguageModeling\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CA1YjYVuM_o6"
      },
      "source": [
        "## Predicting the next note using GPT2\n",
        "[HuggingFace](https://huggingface.co/transformers/v4.8.1/task_summary.html#)\n",
        "\n",
        "[Class GPT2Config](https://huggingface.co/transformers/v2.5.0/_modules/transformers/configuration_gpt2.html)\n",
        "This is the config that needs to be passed to GPT2Model Classes.\n",
        "\n",
        "[Class GPT2LMHeadModel](https://huggingface.co/docs/transformers/model_doc/gpt2#transformers.GPT2LMHeadModel)\n",
        "Here we use the GPT2 Model transformer with a language modeling head on top (linear layer with weights tied to the input embeddings).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HkH8zyZKc_M5"
      },
      "outputs": [],
      "source": [
        "from transformers import GPT2Config, GPT2LMHeadModel\n",
        "\n",
        "model_config = GPT2Config(\n",
        "    vocab_size=tokenizer.vocab_size,\n",
        "    pad_token_id=tokenizer.pad_token_id,\n",
        "    n_ctx=512,\n",
        "    n_embd=512,\n",
        "    n_head=8,\n",
        "    n_layer=9,\n",
        "    n_positions=512,\n",
        ")\n",
        "model = GPT2LMHeadModel(model_config)\n",
        "# model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hy7gARUnxNdB"
      },
      "source": [
        "# Testing the-jam-machine\n",
        "Tristan's script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1AJRUdbxQmU"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "inputs = [random.choice(dataset_train_tokenized)]\n",
        "inputs = data_collator(inputs)\n",
        "assert list(inputs.keys()) == [\"input_ids\", \"attention_mask\", \"labels\"], list(inputs.keys())\n",
        "print(\"input_ids:\", inputs[\"input_ids\"])\n",
        "print(\"\")\n",
        "\n",
        "outputs = model(**inputs)\n",
        "assert list(outputs.keys()) == [\"loss\", \"logits\", \"past_key_values\"], list(outputs.keys())\n",
        "print(\"logits:\", outputs[\"logits\"])\n",
        "\n",
        "plt.plot(outputs[\"logits\"].detach().numpy()[0][0])\n",
        "plt.title(\"Logits\")\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "activations = torch.nn.functional.softmax(outputs[\"logits\"], dim=-1)\n",
        "plt.plot(activations.detach().numpy()[0][0])\n",
        "plt.title(\"Activations\")\n",
        "plt.show()\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7qgxTiiiM-t"
      },
      "source": [
        "## Generating from a given input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PqDAsmj-f4F5"
      },
      "outputs": [],
      "source": [
        "def tokenize_text_input(text_input, verbose=True, model=model, tokenizer=tokenizer):\n",
        "  input_ids = tokenizer.encode(text_input, return_tensors=\"pt\")#.cuda()\n",
        "  if verbose:\n",
        "    print(f\"inputs: {tokenizer.decode(input_ids[0])}\")\n",
        "  return input_ids\n",
        "\n",
        "def generate_the_next_bars(input_ids, verbose=False, model=model, tokenizer=tokenizer):\n",
        "  generated_ids = model.generate(\n",
        "    input_ids,\n",
        "    max_length=512,\n",
        "    do_sample=True,\n",
        "    temperature=0.75,\n",
        "    eos_token_id=tokenizer.encode(\"TRACK_END\")[0] \n",
        ")\n",
        "  if verbose:\n",
        "    print(f\"output: {generated_ids}\")\n",
        "  return generated_ids\n",
        "\n",
        "def convert_ids_to_text(generated_ids, verbose=True, tokenizer=tokenizer):\n",
        "  generated_text = tokenizer.decode(generated_ids[0])\n",
        "  if verbose:\n",
        "    print(f\"output: {generated_text}\")\n",
        "  return generated_text\n",
        "\n",
        "# To generate, Run:\n",
        "#generated_text = convert_ids_to_text(generate_the_next_bars(tokenize_text_input(text_input)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Q1-1N2juU2o",
        "outputId": "66d04c9c-3de5-4633-cc1b-19a5d8a200fc"
      },
      "outputs": [],
      "source": [
        "# Generated from the untrained model\n",
        "text_input = \"PIECE_START TRACK_START INST=25\"\n",
        "generated_text = convert_ids_to_text(generate_the_next_bars(tokenize_text_input(text_input)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLcy5V29cJ5R"
      },
      "source": [
        "# Train the-jam-machine\n",
        "Tristan's script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-HXku8HadJE2"
      },
      "outputs": [],
      "source": [
        "# do we train from scratch?\n",
        "# train_from_scratch = False\n",
        "train_from_scratch = train_from_scratch\n",
        "#imports\n",
        "from transformers import TrainingArguments, Trainer\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pH99bb2cABm_"
      },
      "source": [
        "Check those links (Hugging Face): \n",
        "- [Trainer](https://huggingface.co/docs/transformers/main_classes/trainer)\n",
        "\n",
        "- [TrainingArguments](https://huggingface.co/transformers/v4.3.3/_modules/transformers/training_args.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "id": "NRoqheCiA4mQ",
        "outputId": "a97760a9-49a3-4717-ec3c-0a130d508062"
      },
      "outputs": [],
      "source": [
        "# Weight and Biases\n",
        "import wandb\n",
        "wandb.init(project=\"the-jam-machine-test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nri9kxDTra46"
      },
      "outputs": [],
      "source": [
        "# GPU troubvleshooting\n",
        "# !nvidia-smi\n",
        "# !kill process_id\n",
        "# !ps -aux|grep python\n",
        "# !torch.cuda.memory_summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewSsVg0LGTMr"
      },
      "source": [
        "## Train from scratch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9NlNnxc3Rjc"
      },
      "outputs": [],
      "source": [
        "train_from_this_checkpoint = None\n",
        "train_from_this_checkpoint_model_path = model_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRRFN-fX3SO7"
      },
      "source": [
        "## Train from a checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVYvJAhp3Vzz"
      },
      "outputs": [],
      "source": [
        "if not train_from_scratch:\n",
        "  train_from_this_checkpoint_model_path = \"/content/drive/MyDrive/the_jam_machine/model_firsttry/\"\n",
        "  train_from_this_checkpoint = \"checkpoint-3300\"\n",
        "  additionnal_epochs_to_run = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "id": "YHLjkDERcMIG",
        "outputId": "321a30b7-7e6d-4cda-dbf2-a20bd5b1ea2f"
      },
      "outputs": [],
      "source": [
        "# Create the trainer.\n",
        "print(\"Creating trainer...\")\n",
        "steps = 500\n",
        "num_train_epochs = 2\n",
        "output_path = train_from_this_checkpoint_model_path\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_path, # where model and checkpoints will be saved\n",
        "    overwrite_output_dir=True,# self-explanatory\n",
        "    num_train_epochs=num_train_epochs, # defaults to 3.0\n",
        "    evaluation_strategy=\"steps\", # Evaluation is done (and logged) every eval_steps (so not at the end of every epoch)\n",
        "    eval_steps=steps, # Number of update steps (backprob) between two evaluations\n",
        "    learning_rate=5e-5, #initial learning rate for :class:`~transformers.AdamW` optimizer.\n",
        "    per_device_train_batch_size=10, #default value is 8\n",
        "    # per_device_eval_batch_size=10, #default value is 8\n",
        "    seed=42, # default seed=42\n",
        "    save_strategy=\"steps\", # \n",
        "    save_steps=steps,\n",
        "    save_total_limit=20,\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_first_step=True,\n",
        "    logging_steps=steps,\n",
        "    logging_dir=os.path.join(output_path, \"logs\"),\n",
        "    prediction_loss_only=False,\n",
        "    report_to=\"wandb\",\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=dataset_train_tokenized,\n",
        "    eval_dataset=dataset_val_tokenized,\n",
        ")\n",
        "\n",
        "  # Train the model.\n",
        "if train_from_scratch:\n",
        "  trainer.train()\n",
        "else:\n",
        "  if train_from_this_checkpoint is not None:\n",
        "    # Load the checkpoint\n",
        "    trainer.args.num_train_epochs += additionnal_epochs_to_run\n",
        "    trainer.train(f\"{train_from_this_checkpoint_model_path}/{train_from_this_checkpoint}/\")\n",
        "  else: # todo\n",
        "    # Load a trained model\n",
        "    pass\n",
        "    \n",
        "  # Save the tokenizer with the model\n",
        "  tokenizer.save_pretrained(output_path)\n",
        "\n",
        "  # Save the model.\n",
        "  model.save_pretrained(output_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wma4U-QNElVt"
      },
      "source": [
        "# Generate from the-jam-machine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "il79vznP_YeC"
      },
      "source": [
        "### Generate from the model just trained"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nE0Xksnr_Xbr"
      },
      "outputs": [],
      "source": [
        "text_input = \"PIECE_START TRACK_START INST=93 NOTE_ON=67\"\n",
        "generated_text = convert_ids_to_text(generate_the_next_bars(tokenize_text_input(text_input)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDp9n0iqF1Sp"
      },
      "source": [
        "### Load a saved the-jam-machine and generate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxsVSEFdF6hm",
        "outputId": "296338e2-0676-4c1d-886c-21c2047d5dca"
      },
      "outputs": [],
      "source": [
        "pre_trained_model_path = \"/content/drive/MyDrive/the_jam_machine/model_firsttry/\"\n",
        "model = torch.load(\n",
        "    f\"{pre_trained_model_path}/pytorch_model.bin\", \n",
        "    map_location=torch.device(\"cpu\")\n",
        ")\n",
        "text_input = \"PIECE_START TRACK_START INST=93 NOTE_ON=67\"\n",
        "generated_text = convert_ids_to_text(generate_the_next_bars(tokenize_text_input(text_input)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0TCWJqGy1w8"
      },
      "source": [
        "# Extras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rn6TBTLJqqxu"
      },
      "source": [
        "## Torch playground"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8eJFXgYAUX1"
      },
      "outputs": [],
      "source": [
        "# import torch.nn as nn\n",
        "lin_test = nn.Linear(512, 512, bias=True)\n",
        "rand_input = torch.randint(0, 1, (512,), dtype=torch.float32)\n",
        "out = lin_test(rand_input)\n",
        "# out\n",
        "print(lin_test.weight)\n",
        "print(lin_test.bias)\n",
        "print(nn.ModuleList([lin_test, lin_test, lin_test]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOjteM03q1Oh"
      },
      "source": [
        "## Tristan's function to visualize a text sequence into midi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dx0meZoXmCP4"
      },
      "outputs": [],
      "source": [
        "# function from the note book to visualize... Does not work here - need to work on it - later\n",
        "!pip install note_seq\n",
        "import note_seq\n",
        "\n",
        "synth = note_seq.midi_synth.synthesize\n",
        "synth = note_seq.midi_synth.fluidsynth\n",
        "\n",
        "NOTE_LENGTH_16TH_120BPM = 0.25 * 60 / 120\n",
        "BAR_LENGTH_120BPM = 4.0 * 60 / 120\n",
        "\n",
        "def token_sequence_to_note_sequence(token_sequence, use_program=True, use_drums=True, instrument_mapper=None, only_piano=False):\n",
        "\n",
        "    if isinstance(token_sequence, str):\n",
        "        token_sequence = token_sequence.split()\n",
        "\n",
        "    note_sequence = empty_note_sequence()\n",
        "\n",
        "    # Render all notes.\n",
        "    current_program = 1\n",
        "    current_is_drum = False\n",
        "    current_instrument = 0\n",
        "    track_count = 0\n",
        "    for token_index, token in enumerate(token_sequence):\n",
        "\n",
        "        if token == \"PIECE_START\":\n",
        "            pass\n",
        "        elif token == \"PIECE_END\":\n",
        "            break\n",
        "        elif token == \"TRACK_START\":\n",
        "            current_bar_index = 0\n",
        "            track_count += 1\n",
        "            pass\n",
        "        elif token == \"TRACK_END\":\n",
        "            pass\n",
        "        elif token.startswith(\"INST\"):\n",
        "            instrument = token.split(\"=\")[-1]\n",
        "            if instrument != \"DRUMS\" and use_program:\n",
        "                if instrument_mapper is not None:\n",
        "                    if instrument in instrument_mapper:\n",
        "                        instrument = instrument_mapper[instrument]\n",
        "                current_program = int(instrument)\n",
        "                current_instrument = track_count\n",
        "                current_is_drum = False\n",
        "            if instrument == \"DRUMS\" and use_drums:\n",
        "                current_instrument = 0\n",
        "                current_program = 0\n",
        "                current_is_drum = True\n",
        "        elif token == \"BAR_START\":\n",
        "            current_time = current_bar_index * BAR_LENGTH_120BPM\n",
        "            current_notes = {}\n",
        "        elif token == \"BAR_END\":\n",
        "            current_bar_index += 1\n",
        "            pass\n",
        "        elif token.startswith(\"NOTE_ON\"):\n",
        "            pitch = int(token.split(\"=\")[-1])\n",
        "            note = note_sequence.notes.add()\n",
        "            note.start_time = current_time\n",
        "            note.end_time = current_time + 4 * NOTE_LENGTH_16TH_120BPM\n",
        "            note.pitch = pitch\n",
        "            note.instrument = current_instrument\n",
        "            note.program = current_program\n",
        "            note.velocity = 80\n",
        "            note.is_drum = current_is_drum\n",
        "            current_notes[pitch] = note\n",
        "        elif token.startswith(\"NOTE_OFF\"):\n",
        "            pitch = int(token.split(\"=\")[-1])\n",
        "            if pitch in current_notes:\n",
        "                note = current_notes[pitch]\n",
        "                note.end_time = current_time\n",
        "        elif token.startswith(\"TIME_DELTA\"):\n",
        "            delta = float(token.split(\"=\")[-1]) * NOTE_LENGTH_16TH_120BPM\n",
        "            current_time += delta\n",
        "        elif token == \"[PAD]\":\n",
        "            pass\n",
        "        else:\n",
        "            #print(f\"Ignored token {token}.\")\n",
        "            pass\n",
        "\n",
        "    # Make the instruments right.\n",
        "    instruments_drums = []\n",
        "    for note in note_sequence.notes:\n",
        "        pair = [note.program, note.is_drum]\n",
        "        if pair not in instruments_drums:\n",
        "            instruments_drums += [pair]\n",
        "        note.instrument = instruments_drums.index(pair)\n",
        "\n",
        "    if only_piano:\n",
        "        for note in note_sequence.notes:\n",
        "            if not note.is_drum:\n",
        "                note.instrument = 0\n",
        "                note.program = 0\n",
        "\n",
        "    return note_sequence\n",
        "\n",
        "def empty_note_sequence(qpm=120.0, total_time=0.0):\n",
        "    note_sequence = note_seq.protobuf.music_pb2.NoteSequence()\n",
        "    note_sequence.tempos.add().qpm = qpm\n",
        "    note_sequence.ticks_per_quarter = note_seq.constants.STANDARD_PPQ\n",
        "    note_sequence.total_time = total_time\n",
        "    return note_sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fWtp1Qq2ltMG"
      },
      "outputs": [],
      "source": [
        "# token_sequence = dataset_train_tokenized[0][\"input_ids\"]\n",
        "# note_sequence = token_sequence_to_note_sequence(token_sequence, only_piano=True)\n",
        "# # note_seq.plot_sequence(note_sequence)\n",
        "# # note_seq.play_sequence(note_sequence, note_seq.midi_synth.fluidsynth)\n",
        "# encoded_sequence = tokenizer.encode(token_sequence)\n",
        "# print(dataset_train_dict[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-F5Gl98p1mdD"
      },
      "source": [
        "## distribution of fake data into train and validation set folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txIpW7nbhpbj"
      },
      "outputs": [],
      "source": [
        "# FAKE DATA\n",
        "# limit the file number\n",
        "# file_number = 20\n",
        "# create the file path name\n",
        "# dataset_path = encoded_midi_path;\n",
        "# dataset_path_all = os.path.join(dataset_path, \"all\")\n",
        "# dataset_path_train = os.path.join(dataset_path, \"train\")\n",
        "# dataset_path_valid = os.path.join(dataset_path, \"valid\")\n",
        "\n",
        "# # organising the dataset if not done already\n",
        "# if not os.path.exists(dataset_path_train):\n",
        "#   for path in [dataset_path, dataset_path_all, dataset_path_train, dataset_path_valid]:\n",
        "#     if not os.path.exists(path):\n",
        "#         os.mkdir(path)\n",
        "\n",
        "#   # Find all the files\n",
        "#   path_all = glob.glob(f\"{dataset_path_all}/*.txt\")\n",
        "\n",
        "#   print(sorted(path_all))\n",
        "#   # Do not use all.\n",
        "#   file_number = 20\n",
        "#   path_all = path_all[:file_number]\n",
        "\n",
        "#   # Split 80/20.\n",
        "#   split_index = int(len(path_all) * 0.8)\n",
        "#   path_train = path_all[:split_index]\n",
        "#   path_valid = path_all[split_index:]\n",
        "\n",
        "#   # Copy files.\n",
        "#   def copy(path, destination):\n",
        "#     for p in path:\n",
        "#       shutil.copy2(p, destination)\n",
        "\n",
        "#   copy(path_train, dataset_path_train)\n",
        "#   copy(path_valid, dataset_path_valid)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.7 ('the-jam-machine-C486_rTm')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "05f180633b6db30f1627d6c6525b2893a825dbfd9b5c1cd1f75c024f33da1787"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
